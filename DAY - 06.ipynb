{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e415046-bd82-4300-9469-c2ba157edd5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Load bronze events table\n",
    "events = spark.table(\"workspace.ecommerce.events_delta\")\n",
    "\n",
    "# Recreate binary label\n",
    "label_df = events.groupBy(\"user_id\").agg(\n",
    "    F.max(\n",
    "        F.when(F.col(\"event_type\") == \"purchase\", 1).otherwise(0)\n",
    "    ).alias(\"purchased\")\n",
    ")\n",
    "\n",
    "# Load silver feature table\n",
    "features_df = spark.table(\"workspace.ecommerce.user_features_silver\")\n",
    "\n",
    "# Recreate training dataset (features + label)\n",
    "training_data = features_df.join(label_df, \"user_id\")\n",
    "\n",
    "print(\"Training dataset recreated successfully!\")\n",
    "training_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a8779f3-a8dd-4fc0-9a56-5abb93903b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"total_events\", \"purchases\", \"total_spent\", \"avg_price\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "ml_data = assembler.transform(training_data).select(\"features\", \"purchased\")\n",
    "\n",
    "print(\"Feature vector created successfully!\")\n",
    "ml_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0073f4b-234e-49f1-abd6-c5a93781a507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"purchased\",\n",
    "    maxIter=20,\n",
    "    regParam=0.1\n",
    ")\n",
    "lr_model = lr.fit(ml_data)\n",
    "\n",
    "print(\"Logistic Regression model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70d36f37-afe2-4e04-adac-7242c42addc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions from Logistic Regression model\n",
    "lr_predictions = lr_model.transform(ml_data)\n",
    "\n",
    "# Evaluate using AUC\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"purchased\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "lr_auc = evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(\"Logistic Regression AUC:\", lr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776db25b-95d9-4172-a7cb-36d1208fa10f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"purchased\",\n",
    "    numTrees=100,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_model = rf.fit(ml_data)\n",
    "\n",
    "print(\"Random Forest model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72062829-f588-420b-932b-f938961de526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions from RandomForest model\n",
    "rf_predictions = rf_model.transform(ml_data)\n",
    "\n",
    "# Evaluate AUC for RandomForest\n",
    "rf_auc = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(\"RandomForest AUC:\", rf_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8946af9-40c8-411b-8954-4719c178253d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Recreate train/test split from training_data\n",
    "train_df, test_df = training_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train/Test recreated successfully!\")\n",
    "print(\"Train count:\", train_df.count())\n",
    "print(\"Test count:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6a77863-8a30-4265-a447-6055d33ad4bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create ML-ready train dataset\n",
    "train_ml = assembler.transform(train_df) \\\n",
    ".select(\"features\", F.col(\"purchased\").alias(\"label\"))\n",
    "\n",
    "# Create ML-ready test dataset\n",
    "test_ml = assembler.transform(test_df) \\\n",
    ".select(\"features\", F.col(\"purchased\").alias(\"label\"))\n",
    "\n",
    "print(\"Train and Test ML datasets prepared!\")\n",
    "print(\"Train ML count:\", train_ml.count())\n",
    "print(\"Test ML count:\", test_ml.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f1bbbf7-ff7b-4584-b10a-e52327538408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Train model\n",
    "lr_final = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    maxIter=20,\n",
    "    regParam=0.1\n",
    ")\n",
    "\n",
    "lr_final_model = lr_final.fit(train_ml)\n",
    "\n",
    "print(\"Final Logistic Regression model trained on TRAIN set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1161a8cd-7814-44a5-abda-0418b09e3ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on TEST data\n",
    "lr_test_predictions = lr_final_model.transform(test_ml)\n",
    "\n",
    "# Create evaluator for AUC\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    "\n",
    ")\n",
    "\n",
    "# Calculate REAL AUC on unseen test data\n",
    "lr_test_auc = evaluator.evaluate(lr_test_predictions)\n",
    "\n",
    "print(\"Final Logistic Regression Test AUC:\", lr_test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9d5adf-af43-4e57-a30e-ad94da611344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrain RandomForest on TRAIN set (correct way)\n",
    "rf_final = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_final_model = rf_final.fit(train_ml)\n",
    "\n",
    "print(\"Final RandomForest model trained on TRAIN set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38d64171-11ba-490b-979f-0fe68b0eede0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on TEST data using final RandomForest model\n",
    "rf_test_predictions = rf_final_model.transform(test_ml)\n",
    "\n",
    "# Calculate REAL AUC on unseen test data\n",
    "rf_test_auc = evaluator.evaluate(rf_test_predictions)\n",
    "\n",
    "print(\"Final RandomForest Test AUC:\", rf_test_auc)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY - 06",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
